{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91714,"databundleVersionId":11251744,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:26:31.872881Z","iopub.execute_input":"2025-03-26T16:26:31.873266Z","iopub.status.idle":"2025-03-26T16:26:32.316328Z","shell.execute_reply.started":"2025-03-26T16:26:31.873229Z","shell.execute_reply":"2025-03-26T16:26:32.315281Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e3/sample_submission.csv\n/kaggle/input/playground-series-s5e3/train.csv\n/kaggle/input/playground-series-s5e3/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Data handling\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocessing\nfrom sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.feature_selection import RFE\n\n# Handling class imbalance\nfrom imblearn.over_sampling import SMOTE\n\n# Models\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# Hyperparameter optimization\nimport optuna\n\n# Metrics\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n\n# Saving models\nimport joblib\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:07.680586Z","iopub.execute_input":"2025-03-26T10:48:07.680962Z","iopub.status.idle":"2025-03-26T10:48:13.048077Z","shell.execute_reply.started":"2025-03-26T10:48:07.680929Z","shell.execute_reply":"2025-03-26T10:48:13.047223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the datasets\ndf_train = pd.read_csv('/kaggle/input/playground-series-s5e3/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s5e3/test.csv')\n\n# Quick look at train dataset\nprint(\"Train Dataset Head:\")\ndisplay(df_train.head())\n\nprint(\"\\nTrain Dataset Info:\")\nprint(df_train.info())\n\n# Check for missing values\nprint(\"\\nMissing values in train:\")\nprint(df_train.isnull().sum())\n\nprint(\"\\nTrain dataset shape:\", df_train.shape)\nprint(\"Test dataset shape:\", df_test.shape)\n\n# Check target variable distribution\nprint(\"\\nTarget distribution (rainfall):\")\nprint(df_train['rainfall'].value_counts(normalize=True))\n\n# Check test dataset columns\nprint(\"\\nTest Dataset Head:\")\ndisplay(df_test.head())\n\nprint(\"\\nMissing values in test:\")\nprint(df_test.isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:13.049202Z","iopub.execute_input":"2025-03-26T10:48:13.049849Z","iopub.status.idle":"2025-03-26T10:48:13.143128Z","shell.execute_reply.started":"2025-03-26T10:48:13.049808Z","shell.execute_reply":"2025-03-26T10:48:13.142123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rename column in train and test\ndf_train.rename(columns={'temparature': 'temperature'}, inplace=True)\ndf_test.rename(columns={'temparature': 'temperature'}, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:17.437281Z","iopub.execute_input":"2025-03-26T10:48:17.437740Z","iopub.status.idle":"2025-03-26T10:48:17.444088Z","shell.execute_reply.started":"2025-03-26T10:48:17.437690Z","shell.execute_reply":"2025-03-26T10:48:17.442869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check and fill missing values in winddirection for test dataset\nif df_test['winddirection'].isnull().sum() > 0:\n    median_wind_dir = df_test['winddirection'].median()\n    df_test['winddirection'].fillna(median_wind_dir, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:29.978033Z","iopub.execute_input":"2025-03-26T10:48:29.978478Z","iopub.status.idle":"2025-03-26T10:48:29.985215Z","shell.execute_reply.started":"2025-03-26T10:48:29.978440Z","shell.execute_reply":"2025-03-26T10:48:29.983974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confirm target imbalance before SMOTE\nrainfall_dist = df_train['rainfall'].value_counts(normalize=True)\nprint(rainfall_dist)\n\n# We'll handle with SMOTE after feature engineering and splitting\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:39.515016Z","iopub.execute_input":"2025-03-26T10:48:39.515470Z","iopub.status.idle":"2025-03-26T10:48:39.523288Z","shell.execute_reply.started":"2025-03-26T10:48:39.515433Z","shell.execute_reply":"2025-03-26T10:48:39.522293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create sine and cosine transformations for the 'day' feature\ndf_train['day_sin'] = np.sin(2 * np.pi * df_train['day'] / 365)\ndf_train['day_cos'] = np.cos(2 * np.pi * df_train['day'] / 365)\n\ndf_test['day_sin'] = np.sin(2 * np.pi * df_test['day'] / 365)\ndf_test['day_cos'] = np.cos(2 * np.pi * df_test['day'] / 365)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:42.442862Z","iopub.execute_input":"2025-03-26T10:48:42.443273Z","iopub.status.idle":"2025-03-26T10:48:42.458428Z","shell.execute_reply.started":"2025-03-26T10:48:42.443244Z","shell.execute_reply":"2025-03-26T10:48:42.457362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['temp_diff'] = df_train['maxtemp'] - df_train['mintemp']\ndf_test['temp_diff'] = df_test['maxtemp'] - df_test['mintemp']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:47.878744Z","iopub.execute_input":"2025-03-26T10:48:47.879229Z","iopub.status.idle":"2025-03-26T10:48:47.886062Z","shell.execute_reply.started":"2025-03-26T10:48:47.879183Z","shell.execute_reply":"2025-03-26T10:48:47.884793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['humidity_index'] = df_train['humidity'] / (df_train['temperature'] + 1)  # Add 1 to avoid division by zero\ndf_test['humidity_index'] = df_test['humidity'] / (df_test['temperature'] + 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:48:59.244189Z","iopub.execute_input":"2025-03-26T10:48:59.244735Z","iopub.status.idle":"2025-03-26T10:48:59.251850Z","shell.execute_reply.started":"2025-03-26T10:48:59.244666Z","shell.execute_reply":"2025-03-26T10:48:59.250747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['windspeed_category'] = pd.cut(df_train['windspeed'], bins=[-0.1, 20, 40, np.inf], labels=['Low', 'Medium', 'High'])\ndf_test['windspeed_category'] = pd.cut(df_test['windspeed'], bins=[-0.1, 20, 40, np.inf], labels=['Low', 'Medium', 'High'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:03.163636Z","iopub.execute_input":"2025-03-26T10:49:03.164140Z","iopub.status.idle":"2025-03-26T10:49:03.181138Z","shell.execute_reply.started":"2025-03-26T10:49:03.164069Z","shell.execute_reply":"2025-03-26T10:49:03.180077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['windspeed_category'], prefix='windspeed_cat')\ndf_test = pd.get_dummies(df_test, columns=['windspeed_category'], prefix='windspeed_cat')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:04.501179Z","iopub.execute_input":"2025-03-26T10:49:04.501571Z","iopub.status.idle":"2025-03-26T10:49:04.514116Z","shell.execute_reply.started":"2025-03-26T10:49:04.501540Z","shell.execute_reply":"2025-03-26T10:49:04.513047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.drop(columns=['id', 'day'], inplace=True)\ndf_test.drop(columns=['id', 'day'], inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:06.757419Z","iopub.execute_input":"2025-03-26T10:49:06.757894Z","iopub.status.idle":"2025-03-26T10:49:06.765069Z","shell.execute_reply.started":"2025-03-26T10:49:06.757852Z","shell.execute_reply":"2025-03-26T10:49:06.763826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add any missing columns in df_test with zeros\nmissing_cols = set(df_train.columns) - set(df_test.columns)\nmissing_cols.discard('rainfall')  # Target shouldn't be added\nfor col in missing_cols:\n    df_test[col] = 0\n\n# Drop extra columns in df_test\nextra_cols = set(df_test.columns) - set(df_train.columns)\nfor col in extra_cols:\n    df_test.drop(columns=[col], inplace=True)\n\n# Reorder test columns to match training set (except target)\nX_train_full = df_train.drop(columns=['rainfall'])\ndf_test = df_test[X_train_full.columns]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:10.814466Z","iopub.execute_input":"2025-03-26T10:49:10.814920Z","iopub.status.idle":"2025-03-26T10:49:10.822853Z","shell.execute_reply.started":"2025-03-26T10:49:10.814880Z","shell.execute_reply":"2025-03-26T10:49:10.821880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Select continuous features for scaling\ncontinuous_features = ['pressure', 'maxtemp', 'temperature', 'mintemp', 'dewpoint',\n                       'humidity', 'cloud', 'sunshine', 'winddirection', 'windspeed',\n                       'temp_diff', 'humidity_index']\n\nscaler = MinMaxScaler()\n\n# Fit on training data and transform both train and test\ndf_train[continuous_features] = scaler.fit_transform(df_train[continuous_features])\ndf_test[continuous_features] = scaler.transform(df_test[continuous_features])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:14.994855Z","iopub.execute_input":"2025-03-26T10:49:14.995337Z","iopub.status.idle":"2025-03-26T10:49:15.012464Z","shell.execute_reply.started":"2025-03-26T10:49:14.995295Z","shell.execute_reply":"2025-03-26T10:49:15.011412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Define features (X) and target (y)\nX = df_train.drop(columns=['rainfall'])\ny = df_train['rainfall']\n\n# Apply SMOTE to create a balanced dataset\nsmote = SMOTE(random_state=42, sampling_strategy=0.7)  # Do not oversample to 1.0 to avoid overfitting\nX_resampled, y_resampled = smote.fit_resample(X, y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:19.360009Z","iopub.execute_input":"2025-03-26T10:49:19.360480Z","iopub.status.idle":"2025-03-26T10:49:19.432197Z","shell.execute_reply.started":"2025-03-26T10:49:19.360438Z","shell.execute_reply":"2025-03-26T10:49:19.430983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_resampled, y_resampled,\n    test_size=0.2,\n    stratify=y_resampled,\n    random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:22.069866Z","iopub.execute_input":"2025-03-26T10:49:22.070276Z","iopub.status.idle":"2025-03-26T10:49:22.080730Z","shell.execute_reply.started":"2025-03-26T10:49:22.070246Z","shell.execute_reply":"2025-03-26T10:49:22.079555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training Set Distribution:\\n\", y_train.value_counts(normalize=True))\nprint(\"Validation Set Distribution:\\n\", y_val.value_counts(normalize=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:23.437013Z","iopub.execute_input":"2025-03-26T10:49:23.437451Z","iopub.status.idle":"2025-03-26T10:49:23.445976Z","shell.execute_reply.started":"2025-03-26T10:49:23.437400Z","shell.execute_reply":"2025-03-26T10:49:23.444770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Define parameter grid for Random Forest\nrf_param_grid = {\n    'n_estimators': [300, 500, 700],\n    'max_depth': [10, 20, 30, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'bootstrap': [True, False]\n}\n\n# Initialize Random Forest model\nrf_base_model = RandomForestClassifier(random_state=42)\n\n# Grid search for Random Forest\nrf_grid_search = GridSearchCV(estimator=rf_base_model, param_grid=rf_param_grid, \n                              cv=3, n_jobs=-1, scoring='roc_auc', verbose=2)\n\n# Fit the grid search\nrf_grid_search.fit(X_train, y_train)\n\n# Save the best tuned model\nrf_model_tuned = rf_grid_search.best_estimator_\nprint(\"âœ… Random Forest tuning complete. Best params: \", rf_grid_search.best_params_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T10:49:27.027352Z","iopub.execute_input":"2025-03-26T10:49:27.027872Z","iopub.status.idle":"2025-03-26T10:58:59.231262Z","shell.execute_reply.started":"2025-03-26T10:49:27.027836Z","shell.execute_reply":"2025-03-26T10:58:59.230136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_val_preds = rf_model_tuned.predict(X_val)\nrf_val_proba = rf_model_tuned.predict_proba(X_val)[:, 1]\nrf_accuracy = accuracy_score(y_val, rf_val_preds)\nrf_roc_auc = roc_auc_score(y_val, rf_val_proba)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:36:00.889052Z","iopub.execute_input":"2025-03-26T11:36:00.889507Z","iopub.status.idle":"2025-03-26T11:36:01.041508Z","shell.execute_reply.started":"2025-03-26T11:36:00.889471Z","shell.execute_reply":"2025-03-26T11:36:01.040665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\nfrom xgboost import XGBClassifier\n\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5)\n    }\n    model = XGBClassifier(**params, objective='binary:logistic', \n                          eval_metric='logloss', use_label_encoder=False, random_state=42)\n    model.fit(X_train, y_train)\n    preds = model.predict_proba(X_val)[:,1]\n    return roc_auc_score(y_val, preds)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)\n\nbest_params_xgb = study.best_params\nprint(\"âœ… XGBoost Optuna best params: \", best_params_xgb)\n\n# Train final tuned XGBoost model\nxgb_model_tuned = XGBClassifier(**best_params_xgb, objective='binary:logistic', \n                                eval_metric='logloss', use_label_encoder=False, random_state=42)\nxgb_model_tuned.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:00:58.959326Z","iopub.execute_input":"2025-03-26T11:00:58.959782Z","iopub.status.idle":"2025-03-26T11:01:20.613434Z","shell.execute_reply.started":"2025-03-26T11:00:58.959743Z","shell.execute_reply":"2025-03-26T11:01:20.612413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_val_preds = xgb_model_tuned.predict(X_val)\nxgb_val_proba = xgb_model_tuned.predict_proba(X_val)[:, 1]\nxgb_accuracy = accuracy_score(y_val, xgb_val_preds)\nxgb_roc_auc = roc_auc_score(y_val, xgb_val_proba)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:36:36.893200Z","iopub.execute_input":"2025-03-26T11:36:36.894266Z","iopub.status.idle":"2025-03-26T11:36:36.950917Z","shell.execute_reply.started":"2025-03-26T11:36:36.894222Z","shell.execute_reply":"2025-03-26T11:36:36.949931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\n# Define parameter grid for LightGBM\nlgbm_param_grid = {\n    'n_estimators': [300, 500, 800],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'max_depth': [5, 10, 15],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.7, 0.8, 1.0]\n}\n\nlgbm_base_model = LGBMClassifier(random_state=42)\n\n# Grid search for LightGBM\nlgbm_grid_search = GridSearchCV(estimator=lgbm_base_model, param_grid=lgbm_param_grid,\n                                cv=3, n_jobs=-1, scoring='roc_auc', verbose=2)\n\nlgbm_grid_search.fit(X_train, y_train)\n\n# Save tuned LightGBM model\nlgbm_model_tuned = lgbm_grid_search.best_estimator_\nprint(\"âœ… LightGBM tuning complete. Best params: \", lgbm_grid_search.best_params_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:17:42.552053Z","iopub.execute_input":"2025-03-26T11:17:42.552418Z","iopub.status.idle":"2025-03-26T11:29:52.596650Z","shell.execute_reply.started":"2025-03-26T11:17:42.552393Z","shell.execute_reply":"2025-03-26T11:29:52.595422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgbm_val_preds = lgbm_model_tuned.predict(X_val)\nlgbm_val_proba = lgbm_model_tuned.predict_proba(X_val)[:, 1]\nlgbm_accuracy = accuracy_score(y_val, lgbm_val_preds)\nlgbm_roc_auc = roc_auc_score(y_val, lgbm_val_proba)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:36:54.249324Z","iopub.execute_input":"2025-03-26T11:36:54.249760Z","iopub.status.idle":"2025-03-26T11:36:54.306297Z","shell.execute_reply.started":"2025-03-26T11:36:54.249729Z","shell.execute_reply":"2025-03-26T11:36:54.305365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nstacking_model = StackingClassifier(\n    estimators=[\n        ('rf', rf_model_tuned),\n        ('xgb', xgb_model_tuned),\n        ('lgbm', lgbm_model_tuned)\n    ],\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5, n_jobs=-1\n)\n\nstacking_model.fit(X_train, y_train)\nprint(\"âœ… Stacking model training complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:31:01.871850Z","iopub.execute_input":"2025-03-26T11:31:01.872255Z","iopub.status.idle":"2025-03-26T11:31:20.878077Z","shell.execute_reply.started":"2025-03-26T11:31:01.872228Z","shell.execute_reply":"2025-03-26T11:31:20.876984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stack_val_preds = stacking_model.predict(X_val)\nstack_val_proba = stacking_model.predict_proba(X_val)[:, 1]\nstack_accuracy = accuracy_score(y_val, stack_val_preds)\nstack_roc_auc = roc_auc_score(y_val, stack_val_proba)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:37:13.286658Z","iopub.execute_input":"2025-03-26T11:37:13.287076Z","iopub.status.idle":"2025-03-26T11:37:13.520065Z","shell.execute_reply.started":"2025-03-26T11:37:13.287046Z","shell.execute_reply":"2025-03-26T11:37:13.519261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n\n# Random Forest evaluation\nrf_val_preds = rf_model_tuned.predict(X_val)\nrf_val_proba = rf_model_tuned.predict_proba(X_val)[:, 1]\nrf_accuracy = accuracy_score(y_val, rf_val_preds)\nrf_roc_auc = roc_auc_score(y_val, rf_val_proba)\n\nprint(f\"âœ… Random Forest Accuracy: {rf_accuracy:.4f}\")\nprint(f\"âœ… Random Forest ROC-AUC: {rf_roc_auc:.4f}\")\nprint(\"Random Forest Classification Report:\")\nprint(classification_report(y_val, rf_val_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:37:19.397068Z","iopub.execute_input":"2025-03-26T11:37:19.397515Z","iopub.status.idle":"2025-03-26T11:37:19.581811Z","shell.execute_reply.started":"2025-03-26T11:37:19.397478Z","shell.execute_reply":"2025-03-26T11:37:19.580665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models_comparison = {\n    'Random Forest': {'Accuracy': rf_accuracy, 'ROC_AUC': rf_roc_auc},\n    'XGBoost': {'Accuracy': xgb_accuracy, 'ROC_AUC': xgb_roc_auc},\n    'LightGBM': {'Accuracy': lgbm_accuracy, 'ROC_AUC': lgbm_roc_auc},\n    'Stacking Model': {'Accuracy': stack_accuracy, 'ROC_AUC': stack_roc_auc}\n}\n\ncomparison_df = pd.DataFrame(models_comparison).T\nprint(\"âœ… Models Performance Comparison:\")\ndisplay(comparison_df)\n\nbest_model_name = comparison_df['ROC_AUC'].idxmax()\nprint(f\"ðŸš€ The best model to use for test prediction is: **{best_model_name}**\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:37:31.918099Z","iopub.execute_input":"2025-03-26T11:37:31.918567Z","iopub.status.idle":"2025-03-26T11:37:31.936594Z","shell.execute_reply.started":"2025-03-26T11:37:31.918528Z","shell.execute_reply":"2025-03-26T11:37:31.935464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Align test features to match training columns (excluding rainfall)\nX_test_final = df_test[X_train.columns]\nprint(f\"âœ… Test feature shape after alignment: {X_test_final.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:45:37.206965Z","iopub.execute_input":"2025-03-26T11:45:37.207435Z","iopub.status.idle":"2025-03-26T11:45:37.216079Z","shell.execute_reply.started":"2025-03-26T11:45:37.207404Z","shell.execute_reply":"2025-03-26T11:45:37.215053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# If id column not present, re-load test dataset ID column or extract from original test set\nif 'id' not in df_test.columns:\n    # Reload test data to retrieve ID\n    original_test = pd.read_csv('/kaggle/input/playground-series-s5e3/test.csv')\n    ids = original_test['id']\nelse:\n    ids = df_test['id']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:51:22.031357Z","iopub.execute_input":"2025-03-26T11:51:22.031898Z","iopub.status.idle":"2025-03-26T11:51:22.044075Z","shell.execute_reply.started":"2025-03-26T11:51:22.031866Z","shell.execute_reply":"2025-03-26T11:51:22.043032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_final = df_test[X_train.columns]\ntest_predictions = stacking_model.predict(X_test_final)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:54:33.093641Z","iopub.execute_input":"2025-03-26T11:54:33.094119Z","iopub.status.idle":"2025-03-26T11:54:33.224475Z","shell.execute_reply.started":"2025-03-26T11:54:33.094088Z","shell.execute_reply":"2025-03-26T11:54:33.223256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': ids,\n    'rainfall': test_predictions\n})\n\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:55:00.546216Z","iopub.execute_input":"2025-03-26T11:55:00.546813Z","iopub.status.idle":"2025-03-26T11:55:00.556897Z","shell.execute_reply.started":"2025-03-26T11:55:00.546763Z","shell.execute_reply":"2025-03-26T11:55:00.556002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('/kaggle/working/final_stacking_submission.csv', index=False)\nprint(\"âœ… Final submission file saved and ready for upload!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T11:55:46.029608Z","iopub.execute_input":"2025-03-26T11:55:46.030087Z","iopub.status.idle":"2025-03-26T11:55:46.045007Z","shell.execute_reply.started":"2025-03-26T11:55:46.030047Z","shell.execute_reply":"2025-03-26T11:55:46.044065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}